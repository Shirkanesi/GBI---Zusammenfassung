\documentclass{article}

% Sonderzeichen ermöglichen
\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{a4wide}
\usepackage{xcolor}


\setcounter{tocdepth}{4}
\setcounter{secnumdepth}{4}

%
\newcommand{\myName}{Julian Keck | uwgmn}
\newcommand{\creationYear}{2021}

%Kopf und Fußzeile
\usepackage{scrlayer-scrpage}
\pagestyle{scrheadings}
\ihead{}
\chead{}
\ohead{}

\cfoot{\pagemark}
\rofoot{\small{\textcopyright}  \myName $\;$-$\;$\creationYear}
 %\pagemark

%Subtitle
\usepackage{relsize}
\newcommand{\subtitlerelsize}{1} %relative size: integer value
\newcommand{\subtitlelinesep}{0.1em} %line separation: a LaTeX length

% Hyperlinks in das Dokument einfügen
\usepackage{hyperref}

% Mathe-Packages einbinden
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

% Graphen
\usepackage{tikz}
\usetikzlibrary{trees}

\renewcommand\labelenumi{(\roman{enumi})}
\renewcommand\theenumi\labelenumi

%Farbdefinitionen
\definecolor{strongColor}{RGB}{189, 66, 0}
\definecolor{lightblue}{RGB}{0, 140, 232}
\definecolor{importantColor}{RGB}{163, 19, 0}
\definecolor{ForestGreen}{RGB}{34,139,34}

% Eigene Befehlsdefinitionen
\newcommand{\N}{\mathbb{N_+}} %Natürliche Zahlen (ohne 0)
\newcommand{\Nz}{{\mathbb{N}_0}} %Natürliche Zahlen (mit 0)
\newcommand{\Z}{\mathbb{Z}} % Ganze Zahlen
\newcommand{\Q}{\mathbb{Q}} % Rationale Zahlen
\newcommand{\R}{\mathbb{R}} % Reelle Zahlen
\newcommand{\vektor}[1]{\begin{pmatrix}#1\end{pmatrix}} %Vetoren

\newcommand{\leer}{$\varepsilon$}
\newcommand{\deq}{$\dot{=}$}

\newcommand{\kapitel}[2]{Kapitel #1 - \textsc{#2}}

\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\babyblue}[1]{\textcolor{lightblue}{#1}}

\newcommand{\strongColor}[1]{\textcolor{strongColor}{#1}}
\newcommand{\strong}[1]{\textbf{\strongColor{#1}}}

\newcommand{\important}[1]{\textcolor{importantColor}{#1}}
\newcommand{\verweis}[1]{\textcolor{ForestGreen}{#1}}

\newcommand{\example}[1]{\textit{Beispiel: }#1}
\newcommand{\word}[1]{\blue{\texttt{#1}}}
\newcommand{\interpretation}[1]{\babyblue{#1}}
\newcommand{\set}[1]{\{#1\}}
\newcommand{\anfuehrung}[1]{\flqq #1\frqq}

\newcommand{\w}{\textsf{w}}

\newcommand{\wsp}{\word{\tiny $\sqcup$}}
\newcommand{\wnot}{$\,$\word{$\lnot$}$\,$}
\newcommand{\wand}{$\,$\word{$\land$}$\,$}
\newcommand{\wor}{$\,$\word{$\lor$}$\,$}
\newcommand{\wimpl}{$\,$\word{$\rightarrow$}$\,$}
\newcommand{\wall}{$\,$\word{$\forall$}$\,$}
\newcommand{\wexist}{$\,$\word{$\exists$}$\,$}
\newcommand{\val}[2]{val$\null_{#1}$(#2)}
\newcommand{\valdib}[1]{val$\null_{D,I\beta}$#1}

\newcommand{\Fbox}[1]{\fbox{\strut#1}}
\setlength{\fboxsep}{1pt}% Just for this example
\setlength{\parindent}{0pt}% Just for this example

\newcommand*{\mystrut}{\rule[-0.05\baselineskip]{0pt}{2\baselineskip}}
\newcommand*{\wordbox}[1]{\Fbox{#1}}


\newtheorem{satz}{Satz}
\newtheorem{aufgabe}{Aufgabe}
\newtheorem*{tipp*}{Tipp}
\setlength{\parindent}{0px}

\begin{document}
\title{Zusammenfassung GBI [im WS20/21]\\[\subtitlelinesep]%
    \smaller[\subtitlerelsize]{}Version 1}
\author{Julian Keck\\uwgmn}
%\date{10.12.2020}
\date{\today}
\maketitle

\tableofcontents

\newpage

\section{\kapitel{2}{Signale, Nachrichten, Informationen, Daten}}
\subsection{Signal}
\begin{itemize}
    \item Physikalische Vorgänge vermitteln einen \dq Eindruck\dq{} dessen, was mitgeteilt werden soll.
\end{itemize}

\subsection{Mitteilung}
\begin{itemize}
    \item Wird als Inschrift gespeichert
    \item Ein Gebilde, um etwas als Signal zu speichern
    \item Speichermethoden wie Höhle/Pinsel, Papier/Stift, Eisen/Magnet...
\end{itemize}

\subsection{Nachricht}
\begin{itemize}
    \item Das, was da steht, also unabhängig von Signal/Speichermethode ist.
    \item \example{\blue{10001}: Eins Null Null Null Eins}
    \item \red{10001} ist immernoch die gleiche Nachricht!
    \item Abstraktion der Mitteilung; \red{Un}abhängig von der Art der Speicherung/des Transports.
\end{itemize}

\subsection{Information}
\begin{itemize}
    \item Informationen erhält man durch \strong{Interpretation} einer Nachricht.
    \item Einer Nachricht wird eine Bedeutung zugeordnet
    \item Diese Interpretation erfolgt im \strong{Kopf} und nicht im Computer!
    \item Die Interpretation einer Nachricht kann unterschiedlich sein:\\\example
    \begin{itemize}
        \item \word{10001} interpretieren wir als \interpretation{zehntausendundeins}
        \item \word{10001} kann man auch als \interpretation{17} interpretieren (binär).
        \item oder auch als \interpretation{65537} (\word{10001} als Hexadezimaldarstellung)
    \end{itemize}
    \item Der Rechner hat \dq keine Ahnung\dq{}, was er da tut, macht es aber trotzdem.
\end{itemize}

\subsection{Datum}
\begin{itemize}
    \item Singular von \strong{Daten}, nicht ein Tag im Jahr
    \item Das Bezugssystem der Interpretation ist relevant.
    \item \important{Auf eine Interpretation einigen (und diese festhalten)}
\end{itemize}

\newpage
\section{\kapitel{3}{Mengen, Alphabete, Abbildungen}}
\subsection{Mengen}
\begin{itemize}
    \item Eine Menge ist ein \dq Behälter\dq{} mit \dq Objekten\dq{}
    \item Diese Definition ist gefährlich \verweis{Russle's-Paradoxon}
    \item Eine Menge kann ein Objekt enthalten oder nicht (nicht beides und auch nicht keines von beidem)
    \item \example{$\strongColor{A} = \{1,2,3\}$} ist eine Menge
    \item Auf Mengen kann man die bekannten Operationen wie Mengenschnitt ($\cap$), Mengenvereinigung ($\cup$) und Mengendifferenz ( $\setminus$ ) ausführen
    \item Teilmengenrelationen seien von jetzt an bekannt ($\subsetneq, \subseteq$); auf $\subset$ sollte verzichtet werden.
    \item Sei $A$ eine endliche Menge\footnote{Wir beschränken und in GBI auf endliche Mengen. Es gibt zwar auch die Kardinalität unendlicher Mengen, diese sind aber etwas komplizierter definiert und in GBI sowieso nicht wirklich hilfreich.}. Dann bezeichnet $|A|$ die \strong{Kardinalität} von $A$, also genau die Anzahl der Elemente in $A$
\end{itemize}

\subsection{Alphabet}
\begin{itemize}
    \item Ein Alphabet ist eine nichtleere Menge von Zeichen oder Symbolen
    \item Was ein Zeichen ist, sei nicht weiter spezifiziert\footnote{Dies sollte aus dem täglichen Leben bereits bekannt sein. Beispielsweise ist \word{a} oder \word{x} ein Zeichen. Genauso aber auch \word{$\int$}}, es handelt sich um einen elementaren Baustein von Inschriften
    \item \example{}
    \begin{itemize}
        \item Das deutsche Alphabet
        \item $A=\{\word{0,1}\}$ (\interpretation{Alphabet aller binären Worte})
        \item $A=\{\word{0,1,2,3,4,5,6,7,8,9,A,B,C,D,E,F}\}$ (\interpretation{Alphabet aller hexadezimalen Worte})
        \item ASCII
    \end{itemize}
    \item Manchmal sind Zeichen auch etwas abstrakter, \example{\word{\wordbox{int} \wordbox{counter} \wordbox{=} \wordbox{42} \wordbox{;}}}
\end{itemize}

\subsection{Paare}
\begin{itemize}
    \item Ein Paar $(a, b)$ hat die erste Komponente $a$ und die zweite $b$.
    \item Im Allgemeinen gilt: $(a, b) \neq (b, a)$
\end{itemize}

\subsection{Kartesische Produkt}
\begin{itemize}
    \item Seien $A, B$ zwei Mengen
    \item Das \important{kartesische Produkt $A \times B$} ist definiert als: $A \times B = \{(a,b)\mid a\in A\land \and b\in B\}$ 
    \item $A^2 := A \times A$
\end{itemize}

\newpage

\section{\kapitel{4}{Wörter (und Sprachen)}}
\subsection{Wörter}
\begin{itemize}
    \item \example
    \begin{itemize}
        \item \word{Apfelmus}
        \item \word{Milchreis} - Symbole dürfen also auch mehrfach vorkommen
    \end{itemize}
    \item Das Leerzeichen betrachten wir auch als Zeichen. Manchmal schreiben wir explizit \wsp
    \item \word{Hallo\wsp Welt} ist \important{eine} Folge von Zeichen, also \important{ein} Wort und nicht zwei.
    \item Formalere Definition eines Wortes:
    \begin{itemize}
        \item $\Z_n :=$ "die n kleinsten nichtnegativen ganzen Zahlen"\\
        $\Z_n := \set{i \in \N \mid 0\leq i < n}$\\
        \example$\Z_0 = \set{}, \Z_1 = \set{0}, \Z_4 = \set{0,1,2,3}$
        \item Ein Wort über dem Alphabet $A$ ist eine \important{surjektive Abbildung}:\\
        $\w: \Z_n \to B$  mit $B\subseteq A$ 
        \item \important{$|w| := n$} ist die Länge des Wortes
        \item Das Wort der Länge 0 wird als \important{leeres Wort} oder \important{\leer} bezeichnet.
    \end{itemize}
    \item Die Menge aller Wörter der Länge $n$ wird als \important{$A^n$} geschrieben.\\\example
    \begin{itemize}
        \item $A^0=\{$\leer$\}$
        \item $A^1 = A = \set{\word{a,b}}$
        \item $A^3 = \set{\word{aaa,aab,aba,abb,baa,bab,bba,bbb}}$
    \end{itemize}
    \item Die Menge aller Wörter über dem Alphabet $A$ wird als $A^*$ geschrieben\\
    $A^*=A^0\cup A^1\cup\dots$ oder $\displaystyle{A^* = \bigcup_{i\in \Nz}A^i}$, wenn man eine Notation ohne Pünktchen bevorzugt.
    \item Die Konkatenation bezeichnet die Aneinanderreihung mehrerer Worte, geschrieben wird diese durch \strong{$\cdot$}\\
    \example\\ $x = \word{Hallo}, y = \word{Welt}$\\
    $xy:=x\cdot y = \word{HalloWelt}$
    \item Die Konkatenation ist im Allgemeinen \red{nicht} kommutativ.\\ \example\\ $\word{SCHRANK} \cdot \word{SCHLÜSSEL} = \word{SCHRANKSCHLÜSSEL} \neq \word{SCHLÜSSELSCHRANK} = \word{SCHLÜSSEL} \cdot \word{SCHRANK}$
    \item Die Potenzen von Wörtern sind induktiv definiert durch:\\
    $\forall \:\w \in A^*:\quad$$\w^0=$ \leer\qquad$\w^{n+1}=\w^n\cdot \w$
    
    \subsection{Binäre Operation}
    \begin{itemize}
        \item Eine \important{binäre Operation} auf einer Menge $M$ ist eine Abbildung $f: M\times M \to M$
        \item Oftmals wird eine Infixschreibweise benutzt, \example statt $+(3,8)=11$ schreibt man $3+8=11$
        \item Eine binäre Operation $\star$ ist \strong{kommutativ}, wenn gilt:
        \[ \forall x \in M \:\forall y \in M: \quad x\star y = y \star x \]
        \item Eine binäre Operation $\star$ ist \strong{assoziativ}, wenn gilt:
        \[ \forall x,y,z \in M: \quad (x\star y)\star z = x \star (y \star z) \]
    \end{itemize}
\end{itemize}

\newpage

\section{\kapitel{5}{Aussagenlogik}}
\subsection{Aussagen}
\begin{itemize}
    \item Aussagen sind \important{objektiv} wahr oder falsch \\\example
    \begin{itemize}
        \item \anfuehrung{Die Abbildung $f: \R \to \R: x \mapsto \sqrt{x}$ ist injektiv} \qquad \textbf{ wahr}
        \item \anfuehrung{Die Abbildung $f: \R \to \R: x \mapsto \sqrt{x}$ ist surjektiv} \qquad \textbf{falsch}
    \end{itemize}
    \item Es gibt auch scheinbar sinnvolle Aussagen, die in Wirklichkeit aber sinnlos sind:\\
    \anfuehrung{Ein Barbier ist ein Mann, der genau diejenigen Männer rasiert, die sich nicht selbst rasieren.} 
    \textit{Frage: Wer rasiert den Barbier?}
    \item Jede Aussage besitzt einen \important{eindeutigen Wahrheitswert} (nämlich \strong{wahr} oder \strong{falsch}).
\end{itemize}

\subsection{Aussagenlogische Konnektive}
Seien $P$ und $Q$ zwei Aussagen
\begin{itemize}
    \item \makebox[2.5cm][r]{\textbf{Negation:}} \makebox[2.75cm][r]{\anfuehrung{nicht $P$}:} \strong{$\lnot P$}
    \item \makebox[2.5cm][r]{\textbf{logisches Und:}} \makebox[2.75cm][r]{\anfuehrung{$P$ und $Q$}:} \strong{$P \land Q$}
    \item \makebox[2.5cm][r]{\textbf{logisches Oder:}} \makebox[2.75cm][r]{\anfuehrung{$P$ oder $Q$}:} \strong{$P \lor Q$}
    \item \makebox[2.5cm][r]{\textbf{Implikation:}} \makebox[2.75cm][r]{\anfuehrung{$P$ impliziert $Q$}:} \strong{$P \rightarrow Q$}\\\makebox[5.25cm][r]{\anfuehrung{Wenn $P$, dann $Q$}}
\end{itemize}
Der Wahrheitswert einer \important{zusammengesetzten Aussage} ist durch die Wahrheitswerte der \important{Teilaussagen} \strong{eindeutig} festgelegt. Es gibt keine Abhängigkeit vom konkreten Inhalt der Aussagen, auch nicht bei \anfuehrung{Wenn..., dann...}.

\example
\begin{itemize}
    \item $P:$ \anfuehrung{2014 wurden in Japan etwa 4,7 Mio. PKW neu zugelassen}
    \item $Q:$ \anfuehrung{1999 gab es in Deutschland etwa 11,2 Mio. Internet-Nutzer}
    \item \anfuehrung{Wenn $P$, dann $Q$} ist wahr, da die Teilaussagen wahr sind.
\end{itemize}
Definition des Alphabet der aussagenlogischen Formeln:\\\qquad $A_{AL} := \set{\word{(}, \word{)}, \word{$\lnot$}, \word{$\land$}, \word{$\lor$}, \word{$\rightarrow$}} \cup \set{$Aussagevariablen$}$

Aussagenlogische Formeln sind die Worte aus $A^*_{AL}$, die sinnvoll geklammert und formuliert sind, dies wird im Weiteren nicht betrachtet.\footnote{Die korrekte Klammerung sollte durch den gesunden Menschenverstand ableitbar sein.}

\subsection{Boolsche Funktionen}
\begin{itemize}
    \item Aussagenlogische Formeln sind erstmal nur Zeichenketten.
    \item Sogenannte \important{boolsche Funktionen}:\\
    $f: \mathbb{B}^k \to \mathbb{B}$, \qquad wobei $\mathbb{B}:= \set{\textbf{w}, \textbf{f}}$\\
    sind Funktionen, die Wahrheitswerte auf Wahrheitswerte abbilden. Für die vorher definierten aussagenlogischen Konnektive gibt es die entsprechenden boolschen Funktionen:\\
    $b_{\word{$\lnot$}}(x_1), b_{\word{$\land$}}(x_1, x_2), b_{\word{$\lor$}}(x_1, x_2), b_{\word{$\rightarrow$}}(x_1, x_2)$, wobei diese im Regelfall als Infix notiert werden.
\end{itemize}

\subsection{Bedeutung und Interpretation aussagenlogischer Formeln}
\begin{itemize}
    \item Sei $V$ die Menge von Aussagevariablen
    \item \important{Interpretation} $I: V \to \mathbb{B}$\\
    Dann ist $\mathbb{B}^V$ die Menge aller Interpretationen
    \item Für jede aussagenlogische Formel $F$ ist die \strong{Auswertung} \important{$val_I(F)$} folgendermaßen definiert:
    \begin{align*}
        val_I(\word{$\lnot$} G) &= b_{\word{$\lnot$}}(val_I(G)) \\
        val_I(G\word{$\land$}H) &= b_{\word{$\land$}}(val_I(G), val_I(H)) \\
        val_I(G\word{$\lor$}H) &= b_{\word{$\lor$}}(val_I(G), val_I(H)) \\
        val_I(G\word{$\rightarrow$}H) &= b_{\word{$\rightarrow$}}(val_I(G), val_I(H)) \\
    \end{align*}
    
    \item Zwei Formeln $G$ und $H$ heißen \important{äquivalent}, wenn für jede Interpretation $I$ gilt:\\
    $val_I(G) = val_I(H)$\\
    \example
    \begin{itemize}
        \item \word{\wnot P\wor \wnot Q} und \word{\wnot (P\wand Q)}
        \item \word{\wnot\wnot P} und \word{P}
    \end{itemize}
    \item Geschrieben wird dies als \important{$\equiv$}\\\example{\word{P} $\equiv$ \word{\wnot\wnot P}}
    \item Randbemerkung:\\
    G=\word{P\wand P} und H=\word{Q\wand Q} sind nicht äquivalent, da \word{P} und \word{Q} nicht in jeder Interpretation $I$ den selben Wert haben.
    
\end{itemize}

\subsection{Modelle}
\begin{itemize}
    \item Eine Interpretation $I$ ist \important{Modell} einer Formel $G$, wenn $val_I(G)=$ \textbf{w} ist.
    \item Interpretation I ist \important{Modell} der Formelmenge \strong{$\Gamma$}, wenn gilt:\\
    $\forall G \in \Gamma: val_I(G)=$ \textbf{w}
    \item $\Gamma \models G$ bedeutet: \anfuehrung{Jedes Modell von $\Gamma$ ist auch Modell von $G$}\\
    Definiere: \\$H\models G \quad :\Leftrightarrow \quad \set{H}\models G$\\
    \null\quad$\,\models G \quad :\Leftrightarrow \quad \set{} \models G \quad \Leftrightarrow \quad G$ ist für \important{alle} Interpretationen wahr ($G$ ist eine \strong{Tautologie})\\
    \example{\word{P\wor \wnot P}}
\end{itemize}
\subsection{Beweisbarkeit}
\begin{itemize}
    \item Diese aussagenlogischen Formeln sind alle durch das in der Vorlesung vorgestellte Kalkül beweisbar.\\Dafür werden folgende drei Axiome (tautologe Formeln) definiert: 
    \begin{itemize}
        \item \word{(}G\wimpl \word{(}H\wimpl G\word{)}
        \item \word{(}G\wimpl \word{(}H\wimpl K\word{))}\wimpl\word{((}G\wimpl H\word{)}\wimpl\word{(}G\wimpl K\word{))}
        \item \word{(}\wnot H\wimpl\wnot G\word{)}\wimpl\word{((}\wnot H\wimpl G\word{)}\wimpl H\word{)}
    \end{itemize}
    Als Beweisabschluss gibt es auch noch den \important{Modus Ponens}:\\
    (G\wand\word{(}G\wimpl H\word{)}) $\Rightarrow$ H
\end{itemize}

\newpage
\section{\kapitel{6}{Induktives Vorgehen}}
\subsection{...}
Das induktive Vorgehen sollte aus HM und LA genug bekannt sein, wenn ich Zeit habe, kommt es hier noch dazu.\\
Der Vollständigkeit halber sei es hier aber bereits jetzt erwähnt.

\newpage
\section{\kapitel{7}{Formale Sprachen}}
\subsection{Begriffsklärung und Defnitionen}
\begin{itemize}
    \item Eine \important{formale Sprache} $L$ ist eine Teilmenge aller Wörter eines Alphabetes $A$.\\
    $L\subseteq A^*$
    \item Das Produkt / die Konkatenation zweier formaler Sprachen $L_1$ und $L_2$ ist folgendermaßen definiert:\\
    $L_1L_2 := L_1\cdot L_2 := \set{w_1w_2 \mid w_1 \in L_1 \land w_2 \in L_2}$\\
    \example{$L_1=\set{\word{a}} \qquad L_2=\set{\word{b}} \qquad L_1\cdot L_2=\set{\word{a}}\cdot\set{\word{b}} = \set{\word{a}\cdot\word{b}} = \set{\word{ab}}$}
    \item $\set{\varepsilon}$ ist das neutrale Element der Konkatenation zweier formaler Sprachen:\\
    $\set{\varepsilon}\cdot L = L = L\cdot\set{\varepsilon}$
    \item Die Potenz formaler Sprachen ist naheliegend definiert:
    \begin{align}
        L^0 &= \set{\varepsilon}\\
        \forall n\in\Nz: L^{n+1}&=L\cdot L^n
    \end{align}
\end{itemize}
\subsection{Konkatenationsabschlüsse}
\begin{itemize}
    \item \important{Kleen-Star} / \important{kleensche Hülle}: 
    $L^* = \displaystyle{\bigcup_{i\in\Nz}}L^i$
    \item \important{$\varepsilon$-freier Konkatenationsabschluss}:
    $L^+ = \displaystyle{\bigcup_{i\in\N}}L^i$
    \item Es resultiert: $L^* = L^0 \cup L^+$
    \item \strong{Warnung}: $L^+$ ist nur dann tatsächlich $\varepsilon$-frei, wenn gilt: $\varepsilon\notin L(=L^1)$
    \item Außerdem gilt: $\set{}^*=\set{\varepsilon}$
\end{itemize}

\newpage
\section{\kapitel{8}{Codierungen}}
\subsection{Darstellung von Zahlen}
\begin{itemize}
    \item Seien $Z_{10}=\set{\word{0},\dots,\word{9}}$ die Ziffern.
    \item Die Bedeutung einer Ziffer als Zahl wird durch $num_{10}:Z_{10}\to\Z_{10}$ dargestellt.
    \item $Num_{10}:Z_{10}^*\to\Nz$ gibt die Bedeutung einer Ziffernfolge:\\
    $Num_{10}(x_{k-1}\cdot\cdot\cdot x_1x_0)=10^{k-1}\cdot num(x_{k-1})+\dots 10^1\cdot num_{10}(x_1)+10^0\cdot num_{10}(x_0)$\\
    Bzw.:\\
    $Num_{10}(\varepsilon)=0\qquad Num_{10}(wx)=10\cdot Num_{10}(w)+ num_{10}(x)$
    \item Analoge Definitionen gelten auch für andere Basen, das Ziffernalphabet bis Basis 16 lautet:\\
    $\set{\word{0},\word{1},\word{2},\word{3},\word{4},\word{5},\word{6},\word{7},\word{8},\word{9},\word{A},\word{B},\word{C},\word{D},\word{E},\word{F}}$
    \item Es folgt zwangsläufig eine Uneindeutigkeit\footnote{Hierauf wurde bereits in Kapitel 2 - Information eingegangen.} von Zeichenketten wie \word{111}:
    \begin{itemize}
        \item $Num_{2\hphantom{0}}(\word{111}) = $ \anfuehrung{sieben}
        \item $Num_{8\hphantom{0}}(\word{111}) = $ \anfuehrung{dreiundsiebzig}
        \item $Num_{10}(\word{111}) = $ \anfuehrung{einhundertelf}
        \item $Num_{16}(\word{111}) = $ \anfuehrung{zweihundertdreiundsbiebzig}
    \end{itemize}
\end{itemize}

\subsubsection{Division mit Rest}
Operationen \important{div} und \important{mod}.\\
Es seien $x\in\Nz$ und $y\in\N$:
\begin{itemize}
    \item $x$\textbf{ mod }$y \in \Nz$\\
    Rest der ganzzahligen Division $x$ durch $y$\\
    $0\leq(x$ mod $ y)<y$
    \item $x$\textbf{ div }$y \in \Nz$\\
    Ergebnis der ganzzahligen Division $x$ durch $y$
    \item Es gilt:\\
    $x=y\cdot (x$ div $y)+(x$ mod $y)$
\end{itemize}

\subsubsection{k-äre Darstellung von Zahlen}
Sei $k\in\Nz$ und $k\geq2$
\begin{align*}
    Repr_k:\Nz&\to\Z_k\\
    n&\mapsto 
    \begin{cases}
        repr_k(n), &\text{falls } n<k\\
        Repr_k(n\text{ div }k)\cdot repr_k(n\text{ mod }k), &\text{falls }n\geq k
    \end{cases}
\end{align*}
Es gilt: $Num_k(Repr_k(n))=n$, umgekehrt auch, außer, dass führende Nullen wegfallen.

\subsection{Zweierkomplementdarstellung [ZKPL]}
Sei $l\in\N$:
\begin{itemize}
    \item $\mathbb{K}_l = \set{x\in\Z\mid -2^{l-1}\leq x\leq 2^{l-1}-1}$\\
    \example{$\mathbb{K}_4=\set{-2,-1,0,1}$}
    \item $Zkpl_l: \mathbb{K}_l\to\set{\word{0}, \word{1}}^l$
    \[
        Zkpl_l(x)=
        \begin{cases}
            \word{0}bin_{l-1}(x), &\text{falls }x\geq 0\\
            \word{1}bin_{l-1}(2^{l-1}+x), &\text{falls }x<0
        \end{cases}
    \]
\end{itemize}

\subsection{Notationen für Funktionen}
\begin{itemize}
    \item Menge aller Funktionen von $A$ nach $B$: \important{$B^A:=\set{f\mid f \text{ ist Funktion } f:A\to B}$}\\
    Für endliche Mengen gilt: $|B^A|=|B|^{|A|}$
    \item Die Funktionskomposition, Identität, Umkehrfunktion, Links- und Rechtsinverse sind aus der LA und HM bekannt, und seinen von nun auch hier als bekannt vorausgesetzt.
\end{itemize}

\subsection{Übersetzungen}
\begin{itemize}
    \item Eine Übersetzung verändert den Inhalt der Nachricht nicht. Lediglich die Darstellung wird verändert.
    \item Gründe:
    \begin{itemize}
        \item \important{Legalität}: nur bestimmter Zeichensatz erlaubt
        \item \important{Lesbarkeit}: vergleiche \word{A3} mit \word{10100011}
        \item \important{Verschlüsselung}: keine Lesbarkeit für Ausenstehende
        \item \important{Kompression}: Übersetzungen können kürzer sein, ohne das Alphabet zu vergrößern. \example{Huffman-Codes}
        \item \important{Fehlererkennung} oder \important{Fehlerkorrektur}
    \end{itemize}
\end{itemize}

\subsection{Codierungen}
%Seite 46


\strong{TODO!} Dieses Kapitel folgt noch, dafür habe ich aber momentan keine Lust\\Gleiches gilt für den Kram mit der MIMA

\newpage
\section{\kapitel{11}{Dokumente}}
\subsection{Was sind Dokumente?}
\begin{itemize}
    \item Überall gibt es Inschriften
    \begin{itemize}
        \item Briefe, Kochrezepte, Zeitungsartikel
        \item Seiten im WWW
        \item Diese GBI-Zusammenfassung
    \end{itemize}
    \item DREI Aspekte sind für den Leser relevant:
    \begin{itemize}
        \item \important{Inhalt} des Textes
        \item \important{Struktur} des Textes
        \item \important{Erscheinungsbild} / (äußere) \important{Form} des Textes
    \end{itemize}
    \item In der Regel steht der \strong{Inhalt} für den Autor und Leser im Vordergrund.\\
    Struktur und Form helfen nur beim Verständnis des Inhalts
    \item \important{Dokumente} sind Texte mit Inhalt, Struktur und Form
\end{itemize}
\subsection{Formalisierung von Dokumenten}
Für (nicht allzu) komplexe Regeln, wie ein Dokument auszusehen hat, bieten unsere formalen Sprachen keine ausreichende Methodik, um diese Regeln formal zu definieren. Wir benötigen \verweis{kontextfreie Grammatiken} 

\newpage
\section{\kapitel{12}{Kontextfreie Grammatiken}}
\subsection{Das Problem mit formalen Sprachen...}
\begin{itemize}
    \item Nicht jede Spezifikation (z.B. die Sprache aller Java-Programme) kann mittels formaler Sprache ausgedrückt werden.
    \item \example{Den Block-Syntax von Java kann man folgendermaßen versuchen zu spezifizieren:\\$L=\set{\varepsilon}\cup LL\cup\set{\word{(}}L\set{\word{)}}$}
    \item[$\Rightarrow$]Diese Gleichung ist \important{lösbar}, aber nicht \important{\strong{eindeutig} lösbar}.
\end{itemize}

\subsection{Definition kontextfreier Grammatiken}
\begin{itemize}
    \item Eine kontextfreie Grammatik ist ein 4-Tupel:\\
    $\important{G=(N,T,S,P)}$
    \item \important{$N$} ist das Alphabet der \important{Nichtterminalsymbole}
    \item \important{$T$} ist das Alphabet der \important{Terminalsymbole}
    \item Es gilt stets: $N\cap T = \set{}$
    \item \important{$S \in N$} ist das \important{Startsymbol} 
    \item \important{$P \subseteq N \times (N\cup T)$} ist die \textit{endliche} Menge von \important{Produktionen}
    \begin{itemize}
        \item $(X, w) \in P$ schreibt man als $X \rightarrow w$
        \item Bedeutung: man kann $X$ durch $w$ ersetzen.
        \item Terminalsymbole werden \strong{nicht} ersetzt,\\links des Pfeils stehen also immer Nichtterminalsymbole.
        \item Eine Ersetzung aus $P$ ist immer möglich, also unabhängig vom Kontext (\verweis{$\Rightarrow$ kontextfrei}).
        \item Anstatt $P=\set{X\rightarrow\w_1, X\rightarrow\w_2,X\rightarrow\w_3}$ erlauben wir uns $P=\set{X\rightarrow\w_1\mid\w_2\mid\w_3}$
    \end{itemize}
    \item \example{$G=(\set{X}, \set{\word{a},\word{b}}, X, \set{X\rightarrow\varepsilon, X\rightarrow\word{a}X\word{b}})$}
\end{itemize}
\subsection{Ableitungsschritt}
\begin{itemize}
    \item Die Ableitung von Wörtern erfolgt mittels einer \important{Produktion}: \important{$u\Rightarrow v$}
    \item Das bedeutet: $v\in V^*$ ist in einem Schritt aus $u\in V^*$ ableitbar
    \item \example{$G=(\set{X}, \set{\word{a},\word{b}}, X, \set{X\rightarrow\varepsilon, X\rightarrow\word{a}X\word{b}}), \quad u=\word{a}X\word{b},\quad v=\word{ab}$, dann gilt: $u\Rightarrow v$\\
    Allerdings: ${u} = \word{a}X\word{b},\quad \widetilde{v}=\word{aabb}:\quad u\not\Rightarrow \widetilde{v}$, sondern $u\Rightarrow \word{aa}X\word{bb} \Rightarrow \widetilde{v}$}
    \item Es werden auch \important{Ableitungsfolgen definiert}:\\$u,v\in V^*, \quad i\in \Nz$
    \begin{itemize}
        \item \makebox[1.5cm][l]{\important{$u\Rightarrow^0v$}} gdw. $u=v$
        \item \makebox[1.5cm][l]{\important{$u\Rightarrow^{i+1}v$}} gdw. $\exists\: \w \in V^*: u\Rightarrow w\Rightarrow^iv$
        \item \makebox[1.5cm][l]{\important{$u\Rightarrow^*v$}} gdw. $\exists\: i\in \Nz: u\Rightarrow^iv$
    \end{itemize}
\end{itemize}
\subsection{Jede Grammatik erzeugt eine formale Sprache}
\begin{itemize}
    \item Sei $G=(N,T,S,P)$ eine kontextfreie Grammatik. Dann ist\\
    $L(G)=\set{\w\in T^* \mid S \Rightarrow^* \w} \subseteq T^*$ die \important{erzeugte formale Sprache}
    \item Eine solche Sprache heißt \important{kontextfrei}.
\end{itemize}

\newpage
\section{\kapitel{???}{Relationen}}
\subsection{Definition einer (binären) Relation}
\begin{itemize}
    \item Eine (binäre) Relation $R$ ist eine Teilmenge $R \subseteq M \times M$
    \item Man sagt, $a,b \in M$ sind in Relation, wenn gilt: $(a,b)\in R$
\end{itemize}
\subsection{Produkt von Relationen}
\begin{itemize}
    \item Seien $R\subseteq M_1\times M_2$ und $S\subseteq M_2 \times M_3$ zwei Relationen
    \item Das \important{Produkt der Relationen} $R$ und $S$ ist definiert:\\
    $S\circ R=\set{(x,z)\in M_1 \times M_3 \mid \exists\: y\in M_2: (x,y)\in R \land (y,z)\in S}$
    \item $\circ$ ist assoziativ:\\
    $(T\circ S)\circ R = T\circ(S\circ R)$
    \item Ist $R\subseteq M\times M$ eine binäre Relation auf $M$, dann definiert man die \important{Potenz $R^i$}:
    \begin{align*}
    R^0 &= I_M\\
    \forall i \in \Nz:\:R^{i+1} &= R^i\circ R
    \end{align*}
\end{itemize}
\subsection{Eigenschaften von Relationen}
Sei $R\subseteq M\times M$ eine Relation auf $M$
\begin{itemize}
    \item $R$ heißt \important{reflexiv}, wenn $I_M\subseteq R$, also wenn $\forall\: x \in M: (x,x)\in R$
    \item $R$ heißt \important{transitiv}, wenn $R \circ R\subseteq R$, also wenn \\$\forall\: x,y,z \in M: (x,y)\in R \land (y,z) \in R \Rightarrow (x,z) \in R$
\end{itemize}
\subsection{Reflexiv-transitive Hülle}
\begin{itemize}
    
    \item Die \important{reflexiv-transitive Hülle} einer Relation $R$ ist definiert als: $R^*=\displaystyle{\bigcup_{i\in \Nz}}R^i$
    \item \example{Sei $R=\set{(n, n+1)\mid n\in\Nz}\subseteq\Nz\times\Nz$}
    \begin{align*}
        R\circ R &= \set{(n, n+2)\mid n\in\Nz}\\
        R^0 &= \set{(n,n)\mid n\in\Nz}\\
        R^1 &= \set{(n,n+1)\mid n\in\Nz}\\
        R^2 &= \set{(n,n+2)\mid n\in\Nz}\\
        R^* &= \set{(n,m)\mid n\leq m}
    \end{align*}
\end{itemize}
\subsubsection{Eigenschaften der reflexiv-transisitven Hülle}
\begin{itemize}
    \item $R^*$ ist immer reflexiv\\
    $I_M = R^0\subseteq R^*$
    \item $R^*$ ist immer transitiv
    \item $R^*$ ist die \textit{kleinste} Relation, die R umfasst und reflexiv und transitiv ist.
\end{itemize}

\newpage
\section{\kapitel{13}{Prädikatenlogik - Erste Stufe}}
\subsection{Einführung Prädikatenlogik}
\begin{itemize}
    \item Prädikatenlogische Formeln sind komplizierter aufgebaut als aussagenlogische Formeln
    \item Sie bestehen aus drei Schritten:
    \begin{itemize}
        \item \important{Terme} (Variablensymbole, Konstantensymbole, Funktionssymbole)
        \item \important{Atomare Formeln} (aus Termen, mittels Relationssymbolen)
        \item \important{Prädikatenlogische Formeln} (atomare Formeln unter Verwendung aussagenlogischer \\Konnektive und Quantoren)
    \end{itemize}
\end{itemize}
\subsection{Terme}
\begin{itemize}
    \item \important{Variablensymbole}: Aplhabet $Var_{PL}$
    \begin{itemize}
        \item $\word{x}_i$ (für endlich viele $i\in \Nz$)
        \item kurz auch manchmal \word{x}, \word{y}, \word{z}
    \end{itemize}
    \item \important{Konstantensymbole}: Alphabet $Const_{PL}$
    \begin{itemize}
        \item $\word{c}_i$ (für endlich viele $i\in \Nz$)
        \item kurz auch manchmal \word{c}, \word{d}
    \end{itemize}
    \item \important{Funktionssymbole}: Alphabet $Fun_{PL}$
    \begin{itemize}
        \item $\word{f}_i$ (für endlich viele $i\in \Nz$)
        \item kurz auch manchmal \word{f}, \word{g}, \word{h}
        \item Jedes $\word{f}_i \in Fun_{PL}$ hat \important{Stelligkeit} $ar(\word{f}_i) \in \N$ [engl: \verweis{arity}]
    \end{itemize}
    \item $\Rightarrow A_{Ter}=\set{\word{(}, \word{,}, \word{)}} \cup Var_{PL}\cup Const_{PL}\cup Fun_{PL}$
    \item Aus diesem Alphabet lassen sich alle Terme ableiten, allerdings auch viel Blödsinn. Die korrekte Syntax sei aber von nun an als bekannt vorausgesetzt.\footnote{Die Ursache dafür, dass dies an dieser Stelle nicht weiter betrachtet wird, hat damit zu tun, dass die korrekte Darstellung dieser Grammatik einen großer Haufen Arbeit in \LaTeX  bedarf, wobei die eigentliche Aussage durch relativ einfach und Intuitiv ist.}\\
    \example Korrekte Terme: \quad \word{c\hphantom{y}} \qquad \word{f(x, g(c))} \qquad \word{g(c)}\\
    \example Falsche$\;\;\;$ Terme: \quad \word{xy} \qquad \word{f)x,y( \hphantom{c()}} \qquad \word{c(x)}
\end{itemize}

\subsection{Atomare Formeln}
\begin{itemize}
    \item \important{Relationssymbole}: Alphabet $Rel_{PL}$
    \begin{itemize}
        \item \word{\deq} immer dabei
        \item $\word{R}_i$ (für endlich viele $i\in \Nz$)
        \item kurz auch manchmal \word{R}, \word{S}
        \item Jedes $\word{R}_i \in Rel_{PL}$ hat \important{Stelligkeit} $ar(\word{R}_i) \in \N$ [engl: \verweis{arity}]
    \end{itemize}
    \item $A_{Rel} = A_{Ter}\cup Rel_{PL}$
    \item Aus $A_{Rel}$ können alle gültigen atomaren Formeln abgeleitet werden. Die korrekte Syntax sein von nun an bekannt.\\
    \example \hphantom{nicht }ableitbar: \quad \word{g(x)\deq f(x,g(z))} \qquad \word{S(c)} \qquad \word{R(y,c,g(x))}\\
    \example nicht ableitbar: \quad \word{x\deq y\deq z} \qquad \word{R\deq f} \qquad \word{S(x)\deq S(x)}
\end{itemize}

\subsection{Prädikatenlogische Formeln}
\begin{itemize}
    \item $A_{For} = A_{Rel} \cup \set{\wnot, \wand, \wor, \wimpl, \wall, \wexist}$\\
    \wall \quad \important{Allquantor}\\
    \wexist \quad \important {Existenzquantor}
    \item Aus $A_{For}$ lassen sich alle Prädukatenlogischen Formeln ableiten, die korrekte Syntax sein von nun an bekannt.
\end{itemize}

\subsection{\important{Interpretation} prädikatenlogischer Formeln}
\begin{itemize}
    \item Seien die Alphabete $Const_{PL}$, $Fun_{PL}$, $Rel_{PL}$ gegeben.
    \item Die Interpretation $(D, I)$ besteht aus:
    \begin{itemize}
        \item Der nichtleeren Menge $D$, das \important{Universum} [engl: \verweis{domain}, dt: \verweis{Domäne}]
        \item $I(\word{c}_i \in D$ für $\word{c}_i \in Const_{PL}$
        \item $I(\word{f}_i : D^{ar(\word{f}_i}\to D$ für $\word{f}_i \in Fun_{PL}$
        \item $I(\word{R}_i \subseteq D^{ar(\word{R}_i}\to D$ für $\word{R}_i \in Rel_{PL}$
    \end{itemize}
    \example{Mit $ar(\word{f}) = 2$ und $ar(\word{R})=2$:}
    \begin{itemize}
        \item $D = \Nz$
        \item $I(\word{c})=0$
        \item $I(\word{f}): \Nz^2\to\Nz:(x,y)\mapsto x+y$
        \item $I(\word{R}) = \set{(x,y)\mid x\leq y} \subseteq\Nz^2$
    \end{itemize}
    \item Außerdem gibt es noch die \important{Variablenbelegung} $\beta: Var_{PL}\to D$\\
    \example{$\beta(\word{x})=3$ und $\beta(\word{y})=42$}
    \item Für $\beta$ gibt es noch eine besondere Notation:\\
    Für $\beta: Var_{PL}\to D,\word{x}_i\in Var_{PL}$ und $d\in D$ sei;
    \[ \beta^d_{\word{x}_i}: Var_{PL} \to D: \word{x}_j \mapsto 
    \begin{cases}
        \beta(\word{x}_j), &$falls $j\not=i\\
        d, &$falls $j=i
    \end{cases}
    \]
\end{itemize} 

\subsection{Auswertung von prädikatenlogischen Formeln}
\subsubsection{Ein Wert aus D für jeden Term}
\begin{itemize}
     \item Seien die Alphabete $Const_{PL}$, $Fun_{PL}$, $Rel_{PL}$, sowie die Interpretation $(D,I)$ und die \\Variablenbelegung $\beta$ gegeben.
     \item Wir definieren \important{\valdib{}}$:L_{Ter}\cup L_{For}\to D \cup \mathbb{B}$\\
     Für jeden Term $t\;\;$: \valdib{(t)}$\in D$\\
     Für jede Formel $G$: \valdib{(G)}$\in \mathbb{B}$
     \item \example
     \begin{itemize}
         \item $D=\Nz, I(\word{c})=0, I(f)=$Addition
         \item $\beta(\word{x})=3$ und $\beta(\word{y})=42$
         \item \valdib{(\word{f(y,c)})}\\$=I(\word{f})($\valdib{(\word{y})}, \valdib{(\word{c})}$)$
         \\$=I(\word{f})(\beta(\word{y}), \beta(\word{c}))$
         \\$=I(\word{f})(42, 0)$
         \\$=42+0 = 42$
     \end{itemize}
\end{itemize}
\subsubsection{Wahrheitswerte für atomare Formeln}
\begin{itemize}
    \item Gegeben sei die Interpretation $(D,I)$, sowie die Variablenbelegung $\beta$
    \item Für eine atomare Formel $A \in L_{Rel}$ gibt es zwei Möglichkeiten:\\
    \valdib{($\word{R}_i\word{(}t_1,\dots,t_k\word{)}$)}$=$
    $\begin{cases}
    w, & $falls $ (val_{D,I,\beta}(t_1),\dots, val_{D,I,\beta}(t_k)) \in I(\word{R}_i)\\
    f, & $falls $ (val_{D,I,\beta}(t_1),\dots, val_{D,I,\beta}(t_k)) \notin I(\word{R}_i)
    \end{cases}$
\end{itemize}

\subsubsection{Wahrheitswertt für quantifizierte Formeln}
\begin{itemize}
    \item Gegeben sei die Interpretation $(D,I)$, sowie die Variablenbelegung $\beta$
    \item \valdib{$(\word{\wall x}_i H)$}$=
    \begin{cases}
        w, &$falls \important{für jedes} $ d\in D$ und $\important{\beta'}=\beta^d_{\word{x}_i}$ gilt: val$\null_{D,I,\important{\beta'}}(H)=w\\
        f, &$sonst$
    \end{cases}$
    \item \valdib{$(\word{\wexist x}_i H)$}$=
    \begin{cases}
        w, &$falls \important{für mindestens ein} $ d\in D$ und $\important{\beta'}=\beta^d_{\word{x}_i}$ gilt: val$\null_{D,I,\important{\beta'}}(H)=w\\
        f, &$sonst$
    \end{cases}$
\end{itemize}

\subsection{Allgemeingültige Formeln}
\begin{itemize}
    \item Eine prädikatenlogische Formel $F$ ist \important{allgemeingültig}, wenn:\\
    für jede (passende) Interpretation $(D, I)$ und jede passende Variablenbelegung $\beta$ gilt:\\
    \valdib{(F)}$=w$
\end{itemize}

\subsection{Modelle prädikatenlogischer Formeln}
\begin{itemize}
    \item $(D,I)$ ist \important{Modell für $G\in L_{For}$}, wenn:\\
    $(D,I)$ Interpretation von $G$ und für jedes $\beta$ \valdib{$(G)$}$=w$ ist.
    \item $(D,I)$ ist \important{Modell für $\Gamma\subseteq L_{For}$}, wenn:\\
    $(D,I)$ Modell für jedes $G\in\Gamma$ ist.
    \item \important{$\Gamma\models G$}, wenn jedes Modell von $\Gamma$ auch Modell von $G$ ist.
    \item \important{$H \models G$}, wenn $\set{H}\models G$
    \item \important{$\models G$}, wenn $\set{}\models G$, also wenn $G$ allgemeingültig ist.
\end{itemize}

\subsection{Vorkommen von Variablensymbolen}
\begin{itemize}
    \item Wir betrachten nur die Vorkommen in Termen, nicht die Symbole unmittelbar hinter Quantoren
    \item Die gleiche Variable kann an mehreren Stellen vorkommen
    \item Wir unterscheiden zwischen \important{freien} und \important{gebundenen} Vorkommen
    \item Definitionen:\\
    Die Menge \important{fv$(G)$} der \important{frei} vorkommenden Variablen.\\
    Die Menge \important{bv$(G)$} der \important{gebunden} vorkommenden Variablen.
    %Seite 30
\end{itemize}
Sei $G$ eine atomare Formel
\begin{itemize}
    \item alle Vorkommen von Variablen sind frei
    \item $bv(G)=\set{}$
    \item $fv(G)=\set{$alle in $G$ vorkommende Variablen$}$
\end{itemize}
Sei $G=\wnot H$
\begin{itemize}
    \item $bv(G)=bv(H)\quad$ und $\quad fv(G)=fv(H)$
\end{itemize}
Sei $G \in \set{H_1\wand H_2,\; H_1\wor H_2,\;H_1\wimpl H_2}$
\begin{itemize}
    \item $bv(G)=bv(H_1)\cup bv(H_2)$ und $fv(G)=fv(H_1)\cup fv(H_2)$
    \item Freies Vorkommen in $H_i$ ist freies Vorkommen in $G$
    \item Gebundenes Vorkommen in $H_i$ ist gebundenes Vorkommen in $G$
\end{itemize}
Sei $G$ von der Form $\word{(\wall x}_iH\word{)}$ oder $\word{(\wexist x}_iH\word{)}$
\begin{itemize}
    \item $bv(G)=
    \begin{cases}
    bv(H)\cup\set{\word{x}_i}, &$falls $ \word{x}_i \in fv(H)\\
    bv(H), &$sonst$
    \end{cases}$
    \item $fv(G)=fv(H)\setminus\set{\word{x}_i}$
    \item in $G$ sind alle Vorkommen von $\word{x}_i$ gebunden
    \item Alle anderen Variablen sind wie in H
    \item Die Formel $G$ ist \important{geschlossen}, wenn $fv(G)=\set{}$
\end{itemize}

\subsection{Substitutionen}
\begin{itemize}
    \item Einie \important{Substitution} ist eine Abbildung $\sigma: Var_{PL} \to L_{Ter}$
    \item Falls $\sigma$ durch Menge $S$ der Paare $S=\set{\word{x}_{i_j} / \sigma(\word{x}_{i_j} \mid 1 \leq j \leq k}$ eindeutig bestimmt ist, schreibe:\\
    $\sigma_S = \sigma_\set{\word{x}_{i_j} / \sigma(\word{x}_{i_j}) \mid 1\leq j\leq k}$
    \item \example{$\sigma_\set{\word{x/c, y/f(x)}}$ ist eine Abbildung mit: \\
    $\sigma(\word{x})=\word{c}$\\
    $\sigma(\word{y})=\word{f(x)}$\\
    $\sigma(z)=z$ für alle $z\notin\set{\word{x}, \word{y}}$}
    \item Analog gilt diese Definition auch für Formeln.\\
    Hierbei werden alle \strong{freien} Variablenvorkommen substituiert (und zwar \important{gleichzeitig})
\end{itemize}
\newpage

\section{\kapitel{14}{Algorithmen}}
\subsection{Informelle Definition des Algorithmusbegriffs}
\begin{itemize}
    \item Endliche Beschreibung (man schreibt nur endlich viel Algorithmus, der immer gilt)
    \item Elementare Anweisungen (jedem, mit der Materie vertrauten, ist klar, was gemeint ist)
    \item Determinismus (die nächste Anweisung ist stets eindeutig festgelegt)
    \item Endliche Eingabe $\longrightarrow$ endliche Ausgabe
    \item Endlich viele Schritte
    \item Beliebig große Eingaben sind (theoretisch) bearbeitbar
    \item Nachvollziehbarkeit / Verständlichkeit\\
    \important{Diese Definition ist sehr informell, gibt aber einen ersten Eindruck}
\end{itemize}

\subsection{Beweisbarkeit von Algorithmen -  Hoare-Kalkül / Hoare-Tripel}
\subsubsection{Definition von Hoare-Tripeln}
\begin{itemize}
    \item \important{$\set{P}S\set{Q}$}
    \begin{itemize}
        \item $S$: Programmstück
        \item $P$: \important{Vorbedingung}
        \item $Q$: \important{Nachbedingung}
    \end{itemize}
    \item $P, Q$ sind \important{Zusicherungen}
    \begin{itemize}
        \item prädikatenlogische Formeln
        \item frei vorkommende Variablen, die für das Programm benötigt werden
    \end{itemize}
    \item Wahrheit von Zusicherungen abhängig von Interpretation und Variablenbelegung
    \item \important{\anfuehrung{relevante} Interpretation}: nur \textit{manche} interessieren
    \begin{itemize}
        \item \important{Grundbereich} $D$ [immer fest und explizit definiert]
        \item \important{Funktions-} und \important{Relationssymbole} [naheliegend interpretiert]
        \item \important{Konstantensymbole} beliebig interpretierbar in $D$
        \begin{itemize}
            \item Für \textit{alle} Interpretationen sollen Zusicherungen wahr sein
            \item \anfuehrung{Eingaben} für das Programm
        \end{itemize}
        \item \important{Variablenbelegungen}
        \begin{itemize}
            \item beschreiben den Zustand des \textit{Speichers}
            \item Veränderung durch Zuweisungen
            \item Zuweisung: $x \leftarrow E$ für den Term $E$\\
            vorher Variablenbelegung $\beta$, hinterher $\beta' = \beta^{val_{D,I,\beta}(E)}_x$\\
            Es wird also nur der Wert von $x$ verändert.
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsubsection{Gültigkeit von Hoare-Tripeln}
\begin{itemize}
    \item $\set{P}S\set{Q}$ \important{gültig}, wenn für jede relevante Interpretation $I$ und jede Variablenbelegung $\beta$ gilt:\\
    wenn \important{$val_{D,I,\beta }(P)=w$} und S endet und hinterher $\beta'$ vorliegt,\\
    dann \important{$val_{D,I,\beta'}(Q)=w$}
\end{itemize}

\subsubsection{Axiome und Ableitungsregeln für Hoare-Tripel}
\important{Zuweisungsaxiom}: Wenn
\begin{itemize}
    \item Zuweisung $x\leftarrow E$ mit $E\in L_{Ter}$
    \item $Q$ Nachbedingung zu $x\leftarrow E$
    \item (Die Substitution $\sigma_\set{{x/E}}$ ist kollisionsfrei für $Q$)
\end{itemize}
$\Rightarrow$ Dann gilt \important{HT-A}: \interpretation{$\set{\sigma_{\set{x/E}}(Q)}\;\; x \leftarrow E \;\;\set{Q}$}
\begin{itemize}
    \item Alternative Schreibweise: $\set{Q[x/E]} \;\; x \leftarrow E \;\; \set{Q}$
\end{itemize}
Ableitungsregel für \important{Verstärkung der Vorbedingung} und \important{Abschwächung der Nachbedingung}:
\begin{itemize}
    \item Wenn $P' \rightarrow P$ und $Q \rightarrow Q'$,
    \item Dann \important{HT-E}: $\frac{\set{P}S\set{Q}}{\set{P'}S\set{Q'}}$
\end{itemize}

Ableitungsregel für \important{Hintereinanderausführung}
\begin{itemize}
    \item \important{HT-S}: $\frac{\set{P}S_1\set{Q} \quad \set{Q}S_2\set{R}}{\set{P}S_1;S_2\set{R}}$
\end{itemize}

Regel für \important{bedingte Anweisungen}
\begin{itemize}
    \item \important{HT-I}: $\frac{\set{P \land B}S_1\set{Q} \quad \set{P \land\lnot B}S_2\set{Q}}{\set{P}\; \word{if}\; B\; \word{then}\; S_1\; \word{else}\; S_2\; \word{fi}\; \set{Q}}$
\end{itemize}

Regel für \important{while - Schleifen}
\begin{itemize}
    \item \important{HT-W}: $\frac{\set{I\land B}S\set{I}}{\set{I}\;\word{while}\;B\;\word{do}\;S\;\word{od}\;\set{I\land \lnot B}}$
    \item $I$ ist die \strong{Schleifeninvariante}, sie gilt vor der Schleife, nach jedem Schleifendurchlauf und nach dem Ende der Schleife.
    \item $B$ ist die Schleifenbedingung, die ist nach der Schleife ungültig.
\end{itemize}

\newpage
\section{Graphen}
\subsection{Gerichtete Graphen}
\begin{itemize}
    \item Ein \important{Gerichteter Graph} ist ein Paar $G=(V,E)$
    \begin{itemize}
        \item \important{Knotenmenge $V$}, endlich und nichtleer [\footnote{Knoten engl. \verweis{vertex}}]
        \item \important{Kantenmenge $E$} $\subseteq V\times V$ [\footnote{Kante engl. \verweis{edge}}]\\
        Die Kantenmenge ist endlich, darf aber insbesondere auch \strongColor{leer} sein.
    \end{itemize}
    \item Das Aussehen eines Graphens kann sich unterscheiden, trotzdem handelt es sich noch um den selben Graphen.
    \item \example{\\$V=\set{0,1,2,3}\\E=\set{(0,1),(0,3),(1,2)}$\\
        \begin{tikzpicture}
            \tikzstyle{every node} = [circle, draw]
            
            \node(0) at (0,0){0};
            \node(1) at (1.5, 0){1};
            \node(2) at (0, -1.5) {2};
            \node(3) at (1.5, -1.5) {3};
            
            \foreach \from/\to in {0/1, 0/3, 1/2}
                \draw [->] (\from) -- (\to);
            
            
            \node(a) at (6,0){0};
            \node(b) at (4.5, 0){1};
            \node(c) at (8, 0) {2};
            \node(d) at (5.5, -1) {3};
            
            \foreach \from/\to in {a/b, a/d}
                \draw [->] (\from) -- (\to);
            \draw [->] (b) to [out=30,in=150] (c);    
            
        \end{tikzpicture}
    }
\end{itemize}

\subsubsection{Bäume}
Bäume kamen schon mehrfach vor, daher hier nochmal zur Erinnerung:\\
\begin{tikzpicture}[level distance=1cm,
  level 1/.style={sibling distance=2cm},
  level 2/.style={sibling distance=1cm}]
  \tikzstyle{every node} = [circle, draw]
  \node {\word{1}}
    child {node {\word{10}}
      child {node {\word{100}}}
      child {node {\word{101}}}
    }
    child {node {\word{11}}
    child {node {\word{110}}}
      child {node {\word{111}}}
    };
\end{tikzpicture}

\subsubsection{Teilgraphen}
\begin{itemize}
    \item $G'=(V',E')$ ist ein Teilgraph von $G=(V,E)$, wenn 
    \begin{itemize}
        \item $V'\subseteq V$
        \item $E' \subseteq E\cap V'\times V'$\\
        \important{Endpunkte von Kanten in $E'$ müssen in $V'$ sein!}
    \end{itemize}
\end{itemize}

\subsubsection{Pfade}
\begin{itemize}
    \item \important{$V^{(+)}$}: Menge der nichtleeren Listen von Elementen aus V
    \item \important{$p=(v_0,\dots, v_n)\in V^{(+)}$} ist \important{Pfad}, wenn $\forall i \in \Z_n: \important{(v_i,v_{i+1}) \in E}$
    \item \important{Länge eines Pfades}: Anzahl $n$ der \strong{Kanten}!
    \item $v_n$ von $v_0$ \important{erreichbar}, wenn Pfad $p=(v_0,\dots, v_n)$ existiert
    \item Länge 0 für Pfade erlaubt: $p=(v_0)$
    \item Durch streichen endlich vieler Knoten am Anfang und/oder am Ende erhält man einen Teilpfad.\\Ein Knoten muss mindestens übrig bleiben.
\end{itemize}

\subsubsection{Zyklen}
\begin{itemize}
    \item Pfad mit $v_0=v_n$ heißt \important{geschlossen}
    \item Ein geschlossener Pfad heißt \important{Zyklus}, wenn $n\geq 1$ ist.
    \item Pfad $(v_0,\dots, v_n)$ heißt \important{wiederholungsfrei}, wenn
    \begin{itemize}
        \item Die Knoten $v_0,\dots, v_{n-1}$ und $v_1,\dots, v_{n}$ paarweise verschieden sind
        \item $v_0$ und $v_n$ dürfen gleich sein.
    \end{itemize}
    \item \important{Einfacher Zyklus}: wiederholungsfreier Zyklus
    \item \important{Azyklischer Graph}: kein Teilgraph ist Zyklus
\end{itemize}

\subsubsection{Strenger Zusammenhang}
\begin{itemize}
    \item Ein gerichteter Graph ist \important{streng zusammenhängend}, wenn\\
    $\forall x,y \in V: (x,y)\in V^2 \;\exists$ Pfad von x nach y
\end{itemize}

\subsubsection{Knotengrad im gerichteten Graphen}
\begin{itemize}
    \item \important{Eingangsgrad} eines Knotens $y$ ist:\\
    $d^-(\important{y})=|\set{x\mid(x,\important{y})\in E}|$
    \item \important{Ausgangsgrad} eines Knotens $y$ ist:\\
    $d^+(\important{x})=|\set{y\mid(\important{x}, y)\in E}|$
    \item \important{Grad} eines Knotens ist:
    $d(x) = d^-(x) + d^+(x)$
\end{itemize}

\subsubsection{Gerichtete Bäume}
\begin{itemize}
    \item Es gibt eine \important{Wurzel $r \in V$} mit der Eigenschaft:\\
    \important{zu jedem Knoten $x$} existiert \important{\strong{genau} ein Pfad}
    \item Man kann zeigen: Die Wurzel $r$ ist immer eindeutig
    \item \important{Blätter} sind Knoten mit Ausgangsgrad $=0$
    \item \important{innere Knoten} sind Knoten mit Ausgangsgrad $>0$
\end{itemize}

\subsection{Graphen als Relationen}
\begin{itemize}
    \item $G=(V,E)$ mit $E\subseteq V\times V$ (E binäre Relation auf V)
    \item $(x,z)\in E^2 \iff $Pfad $(x,y,z)$ existiert
    \item $(x,y) \in E^i \iff$ es existiert ein Pfad von $x$ nach $y$ der Länge $i$.
\end{itemize}

\subsection{Ungerichtete Graphen}
\begin{itemize}
    \item Ein \important{ungerichteter Graph} ist eine Struktur $U=(V,E)$ mit
    \begin{itemize}
        \item $V$: endliche nichtleere Menge von \important{Knoten}
        \item $E$: Menge von \important{Kanten} mit $E\subseteq \set{\set{x,y}\mid x\in V \land y\in V}$
        \item Es gibt keine Reihenfolge bei $\set{x,y}$
        \item Beide Knoten gleichberechtigt
    \end{itemize}
    \item \important{adjezente Knoten} sind durch eine Kante miteinander verbunden
    \item Bei einer \important{Schlinge} ist Start und Zielknoten identisch, es ergibt sich also:\\
    $\set{x,y}$ mit $x=y \Rightarrow\set{x}$
    \item Ein Graph ohne Schlinge heißt \important{schlingenfrei}
\end{itemize}
\subsubsection{Teilgraph}
Der Teilgraph des ungerichteten Graphen ist analog zum gerichteten Fall definiert.

\subsubsection{Wege}
\begin{itemize}
    \item \important{$V^{(+)}$}: Menge der nichtleeren Listen von Elementen aus V
    \item \important{$p=(v_0,\dots, v_n)\in V^{(+)}$} ist \important{Weg}, wenn $\forall i \in \Z_n: \important{\set{v_i,v_{i+1}} \in E}$
    \item \important{Länge eines Weges}: Anzahl $n$ der \strong{Kanten}!
    \item $v_n$ von $v_0$ \important{erreichbar}, wenn Weg $p=(v_0,\dots, v_n)$ existiert
    \item Länge 0 für Wege erlaubt: $p=(v_0)$
    %\item Durch streichen endlich vieler Knoten am Anfang und/oder am Ende erhält man einen Teilpfad.\\Ein Knoten muss mindestens übrig bleiben.
\end{itemize}

\subsubsection{Kreise}
\begin{itemize}
    \item \important{geschlossener Weg} oder \important{Kreis}\\
    $p=(v_0,\dots,v_n)$ mit $v_0=v_n$
    \item \important{einfacher Kreis}
    \begin{itemize}
        \item wiederholungsfreier Kreis
        \item mit mindestens \important{drei} verschiedenen Kanten
    \end{itemize}
\end{itemize}

\subsubsection{Zusammenhang}
\begin{itemize}
    \item Ein ungerichteter Graph $U=(V,E)$ heißt \important{zusammenhängend}, wenn der dazugehörige gerichtete Graph $G_U=(V,E_g)$ streng zusammenhängend ist.
\end{itemize}

\subsubsection{Ungerichtete Bäume}
\begin{itemize}
    \item Ein \important{ungerichteter Baum} ist ein ungerichteter Graph $U=(V,E)$, zu dem ein gerichteter Baum $G=(V,E')$ existiert mit $E=E'_u$
    \item Verschiedene gerichtete Bäume induzieren den gleichen ungerichteten Baum
    \item Wurzeln
    \begin{itemize}
        \item Im gerichteten Baum sind Wurzeln eindeutig zu identifizieren
        \item Im ungerichteten Baum kann potentiell jeder Knoten Wurzel sein, diese muss daher explizit angegeben werden.
    \end{itemize}
\end{itemize}

\subsubsection{Knotengrad}
\begin{itemize}
    \item \important{Grad $d(x)$} des Knotens $x\in V$ im ungerichteten Graphen:
    \begin{align*}
        d(x)=|\set{y\mid y\not=x \land \set{x,y} \in E}| + \begin{cases}
        2, &$falls$ \set{x,x} \in E\\
        0, &$sonst$
        \end{cases}
    \end{align*}
    \item Man zählt also die Anzahl der \anfuehrung{Kantenenden}, Schlingen werden \important{doppelt} gezählt.
\end{itemize}

\newpage
\section{Algorithmen in Graphen}
\subsection{Adjazenzmatrix}
\begin{itemize}
    \item Sein $G=(V,E)$ ein ungerichteter Graph mit $n = |V|$ Knoten.
    \item Dann ist die \important{Adjazenzmatrix} $A$ eine $n\times n$-Matrix mit:\\
    $a_{i,j}=\begin{cases}
    1 &$falls $ (i,j)\in E\\
    0 &$falls $ (i,j)\notin E
    \end{cases}$
    \item Salopp gesagt steht überall eine 1, wenn man in \textbf{genau} einem Schritt von $i$ nach $j$ kommt.\\
    (Insbesondere auch bei Schlingen!)
    \item Analog gilt das auch für den ungerichteten Fall
    \item Wir wissen bereits, dass Graphen Relationen darstellen können, daher kann man Relationen auch als Matrix darstellen (auf die naheliegende Weise)
    \begin{itemize}
        \item Sei $M$ endliche Menge mit $|M|=n$ (naheliegend durchnummeriert)
        \item $R\subseteq M\times M$ binäre Relation
        \item Entsprechende Matrix: $A(R)$ ($n\times n$ groß)\\
        $(A(R))_{i,j}=\begin{cases}
        1 &$falls $(i,j)\in R$, also $ iRj\\
        0 &$falls $(i,j)\notin R$, also $ \lnot(iRj)
        \end{cases}$
    \end{itemize}
\end{itemize}


\subsection{Signum-Fuktion}
\begin{itemize}
    \item sgn: $\R\to\R:sgn(x)=\begin{cases}
        1&$falls $x>0\\
        0&$falls $x=0\\
        -1&$falls $x<0\\
    \end{cases}$
    \item Bei Matrizen funktioniert dies komponentenweise.
\end{itemize}

\subsection{Potenzen der Adjazenzmatrix}
\begin{itemize}
    \item Sei $G$ ein gerichteter Graph mit der Adjazenzmatrix $A$.\\
    Für alle $k\in\Nz$ gilt: \\$(A^k)_{i,j}$ ist die Anzahl der Pfade der Länge $k$ in $G$ von $i$ nach $j$.
    \item Es folgt: $sgn((A^k)_{i,j})=\begin{cases}
        1&$falls in $G$ ein Pfad der Länge $k$ von $i$ nach $j$ existiert$\\
        0&$falls in $G$ kein Pfad der Länge $k$ von $i$ nach $j$ existiert$
    \end{cases}$
    \item $sgn(A^k)$ repräsentiert also die Relation $E^k$
\end{itemize}

\subsection{Wegematrix}
\begin{itemize}
    \item Die Wegematrix ist die Matrix $W$ der Erreichbarkeitsrelation $E*$.
    \begin{align*}
        W_{i,j}&=
    \begin{cases}
        1 &$falls $(i,j)\in E^*\\
        0 &$falls $(i,j)\notin E*
    \end{cases}\\
    &=
    \begin{cases}
        1 &$falls es in $G$ einen Pfad von $i$ nach $j$ gibt$\\
        0 &$falls es in $G$ keinen Pfad von $i$ nach $j$ gibt$\\
    \end{cases}
    \end{align*}
    \item Um die Wegematrix effizient berechnen zu können, muss man aber $E^*=\displaystyle{\bigcup_{\important{i\in\Nz}}}E^i$ umschreiben
    \item Es folgt für $G=(V,E)$ mit $|V|=n \in\N$:
    \begin{align*}
        E^*=\bigcup_{i\in\Z_n}E^i = \bigcup_{i\in\Z_k}E^i \quad(\text{für }k\geq n)
    \end{align*}
    \item Sei $G$ ein gerichteter Graph, $A$ seine Adjazenzmatrix.\\
    Dann gilt für alle $k\geq n-1$:
    \begin{itemize}
        \item Die Matrix $sgn\left(\displaystyle{\sum^k_{i=0}A^i}\right)$ repräsentiert die Relation $E^*$
        \item Es gilt also: $W=sgn\left(\displaystyle{\sum^k_{i=0}A^i}\right)$ ist die Wegematrix von $G$.
        \item Dieser Algorithmus ist nicht der effizienteste.\footnote{In der Vorlesung wurde in Kapitel 16 und 17 sehr viel darauf rumgeritten, wie effizient dieser Algorithmus nun ist, oder eben nicht. Dann wurde auch noch der Algorithmus von Strassen eingeführt. Dies dient alles nur zur Vorbereitung auf die "Quantitativen Aspekte von Algorithmen", im Wesentlichen ist dies aber nicht besonders relevant.}
    \end{itemize}
\end{itemize}

\newpage
\section{\kapitel{17}{Quantitative Aspekte von Algorithmen}}
\subsection{Groß-O-Notation}
\subsubsection{(Warum) keine exakten Angaben?}
\begin{itemize}
    \item Man will nicht
    \begin{itemize}
        \item Faulheit
        \item Vergänglichkeit der genauen Werte (bald neuer Prozessor)
        \item Mangelndes Interesse an genauen Werten
    \end{itemize}
    \item Man kann nicht
    \begin{itemize}
        \item Unkenntnis von Randbedingungen
        \item Ungenauigkeiten im \anfuehrung{Algorithmus}\footnote{Wobei es diese ja eigentlich bei einem deterministischen Algorithmus nach unserer Definition gar nicht geben darf}    
    \end{itemize}
    \item Man \anfuehrung{soll} nicht
    \begin{itemize}
        \item Unabhängigkeit von konkreter Probleminstanz
        \item Unabhängigkeit von Programmiersprache
        \item Unabhängig von Prozessor
    \end{itemize}
\end{itemize}

\subsubsection{Genauigkeit}
\begin{itemize}
    \item Ignorieren konstanter Faktoren (genaue Prozessorgeschwindigkeit gibt nur einen konstanten Vorfaktor)
    \item Nur obere (bzw. untere) Schranke angeben (z.B. nur schlechtesten Fall analysieren)
\end{itemize}

\subsubsection{Asymptotisch gleichschnelles Wachstum}
Notation:
\begin{itemize}
    \item $\R_+$: Menge der positiven reellen Zahlen (ohne 0)
    \item $\R_0^+$: Menge der nichtnegativen reellen Zahlen [$\R_0^+=\R_+\cup\set{0}$]
    \item es werden nur Funktionen $f:\Nz\to\R_0^+$ betrachtet
\end{itemize}
Definition:
\begin{itemize}
    \item Die Funktion $g:\Nz\to\R_0^+$ wächst \important{asymptotisch genauso schnell} wie $f:\Nz\to\R_0^+$, wenn gilt:
    \[
        \exists c,c'\in\R_+\;\exists n_0\in\Nz\;\forall n\geq n_0\;:\;\important{cf(n)\leq g(n)\leq c'f(n)}
    \]
    \item schreibe: $\important{f\asymp g}$ oder $\important{f(n)\asymp g(n)}$
    \item \example{
        \begin{itemize}
            \item $f: n\mapsto 3n^2$ und $g: n\mapsto 10^{-2}n^2$
            \item Behauptung: $f\asymp g$
            \item Setze $c=10^{-3}$ und $c'=1$, sowie $m_0=0$:\\
            $cf(n)\leq g(n)\leq c'f(n)$\\
            $10^{-3}\cdot 3n^2\leq 10^{-2}n^2\leq 3n^2$
        \end{itemize}
    }
    \item Regel: $\forall f:\Nz\to\R_0^+\;\forall a,b\in \R_+:\;af\asymp bf$
\end{itemize}
\subsubsection{Äquivalenzrelation $\asymp$}:
\begin{itemize}
    \item $\asymp$ ist eine Äquivalenzrelation, d.h.\\
    $\asymp$ ist
    \begin{itemize}
        \item reflexiv ($f\asymp f$ gilt immer)
        \item transitiv ($(f\asymp g \land g \asymp h) \iff f\asymp h$)
        \item symmetrisch ($f\asymp g \iff g\asymp f$)
    \end{itemize}
\end{itemize}
\subsubsection{Groß $\Theta$}
\begin{itemize}
    \item \important{$\Theta(f)$}: Menge aller Funktionen, die (im Sinne von $\asymp$) zu $f$ äquivalent sind.
    \item $\Theta(f)=\set{g \mid f\asymp g}$
    \item Rechenregel: $\forall\; f:\Nz\to\R_0^+\;\forall a,b\in\R_+:\;\Theta(af)=\Theta(bf)$ 
\end{itemize}

\subsubsection{Obere Schranke O}
\begin{itemize}
    \item \important{$O(f)=\set{g\mid\exists c\in\R_+\;\exists n_0\in\Nz\;\forall n\geq n_0:\;g(n)\leq cf(n)}$}
    \item Schreibweisen:\\
    $g\preceq f \iff g\in O(f)$
\end{itemize}

\subsubsection{Untere Schranke $\Omega$}
\begin{itemize}
    \item \important{$\Omega(f)=\set{g\mid\exists c\in\R_+\;\exists n_0\in\Nz\;\forall n\geq n_0:\;g(n)\geq cf(n)}$}
    \item Schreibweisen:\\
    $g\succeq f \iff g\in \Omega(f)$
\end{itemize}

\subsubsection{Rechenregeln für obere und untere Schranken}
\begin{itemize}
    \item Für alle Funktionen $f,g: \Nz\to\R_0^+$ gilt:\\
    $g\in O(f) \iff f\in\Omega(g)$, also $g\preceq f\iff f\succeq g$
    \item $\Theta(f) = O(f)\cap\Omega(f)$, also:\\
    $g\asymp f \iff (g\preceq f \land g \succeq f)$
    \item Es gilt:\\
    Wenn $g_1\preceq f_1$ und $g_2\preceq f_2$, dann $g_1+g_2 \preceq f_1+f_2$
    \item $\forall f_1,f_2:\Nz\to\R_0^+$ gilt:\\
    $O(f_1)+O(f_2)=O(f1+f2)$
    \item \example $O(n^3+n^2)=O(n^3)$
\end{itemize}

\subsubsection{Komplexoperationen}
\begin{itemize}
    \item Sind $M_1$ und $M;_2$ Mengen, deren Elemente man addieren bzw. multiplizieren kann, dann sei:
    \begin{align*}
        M_1+M_2 &= \set{g_1+g_2 \mid g_1 \in M_1 \land g_2 \in M_2}\\
        M_1\cdot M_2 
        &= \set{g_1 \hphantom{\cdot} \cdot \hphantom{\cdot} g_2 \mid g_1\in M_1 \land g_2\in M_2}
    \end{align*}
    \item Diese Definition ist analog zum Produkt formaler Sprachen
    \item Es gilt außerdem: \\
    statt $\set{n^3}+O(n^2)$ schreibt man $n^3+O(n^2)$
\end{itemize}

\subsection{Teile und herrsche / divide and conquer}
\subsubsection{Definition divide and conquer}
\begin{itemize}
    \item Probleminstanz wird in kleine Teile zerlegt
    \item Diese Teile werden Rekursiv nach gleichem Verfahren bearbeitet
    \item Gesamtergebnis wird aus den Teilergebnissen konstruiert
\end{itemize}

\subsubsection{Laufzeit von Teile-und-Herrsche-Algorithmen}
\begin{itemize}
    \item Problem der Größe $n$ wird zerhackt in \\konstante Anzahl a von Teilproblem gleicher Größe $\frac{n}{b}$
    \item Aus diesen Teilergebnissen wird Gesamtergebnis zusammengesetzt
    \item Aufteilen und Zusammensetzen \anfuehrung{kostet} $f(n)$
    \item Abschätzen der Laufzeit $T(n)$ liefert ungefähr:
    \[\important{T(n)=aT(\frac{n}{b})+f(n)}\]
\end{itemize}

\subsubsection{Master-Theorem}
\begin{itemize}
    \item Fall 1: Wenn \important{$f(n)\in O(n^{(log_ba)-\varepsilon})$}$\;(\varepsilon>0)$, dann $T(n)\in \Theta(n^{log_ba})$
    \item Fall 2: Wenn \important{$f(n)\in O(n^{(log_ba)})$}, dann $T(n)\in \Theta(n^{log_ba}log\:n)$
    \item Fall 3: Wenn \important{$f(n)\in O(n^{(log_ba)+\varepsilon})$}$\;(\varepsilon>0)$, dann $T(n)\in \Theta(f(n))$,\\
    falls zusätzlich auch $\exists \:0<d<1:\;\important{af(\frac{n}{b})\leq df(n)}$ gilt.
    \item Diese Fallunterscheidung ist nicht vollständig!
\end{itemize}

\newpage
\section{\kapitel{18}{Endliche Automaten}}
\subsection{Moore-Automat}
Im WS2020/21 werden nur \important{Moore-Automaten} betrachtet. Mealy-Automaten wurden weggelassen.
\subsubsection{Bestandteile/Definition Moore-Automat}
\begin{itemize}
    \item endliche \important{Zustandsmenge $Z$}\\
    Alle Zustände des Automaten
    \item \important{Anfangszustand} $z_0\in Z$\\
    Der Zustand, indem die \anfuehrung{Ausführung} beginnt.
    \item \important{Eingabealphabet} $X$\\
    Das Alphabet der eingegebenen Wörter
    \item \important{Zustandüberführungsfunktion} $f:Z\times X\to Z$\\
    Gibt an, welcher Zustand kommt, nachdem in dem gegebenen Zustand das Eingegebene Wort eingegeben wurde. 
    \item \important{Ausgabealphabet} Y\\
    Alphabet der ausgegebenen Wörter.
    \item \important{Ausgabefunktion} $h: Z\to Y^*$\\
    Gibt an, welches Wort der angegebene Zustand ausgibt. 
\end{itemize}

\subsubsection{Erweiterung Zustandsüberführungsfunktion}
\begin{itemize}
    \item $f_*$ für den am Ende der Ausführung erreichten Zustand\\
    $f_*:Z\times X^*\to Z$ mit\\
    $f_*(z, \varepsilon) = z$ und $f_*(z, wx)=f(f_*(z,w),x)\quad$ ($w\in X^*, x\in X$)
    \item $f_{**}$ für alle durchlaufenen Zustände\\
    $f_{**}:Z\times X^*\to Z^*$ mit\\
    $f_{**}(z,\varepsilon)=z$ und $f_{**}(z,wx)=f_{**}(z,w)\cdot f_*(z,wx)\quad$ ($w\in X^*, x\in X$)
\end{itemize}

\subsubsection{Erweiterung Ausgabefunktion}
\begin{itemize}
    \item \anfuehrung{letzte Ausgabe}: \important{$g_*=h\circ f_*$}:\\
    $g_*(z,w)=h(f_*(z,w))$
    \item \anfuehrung{alle Ausgaben}: \important{$g_{**}=h^{**}\circ f_{**}$} (induzierter Homomorphismus):\\
    $g_{**}(z,w)=h^{**}(f_{**}(z,w))$\\
    \textit{Es werden alle Ausgaben von Beginn bis Ende hintereinander konkatiniert}
\end{itemize}

\subsection{Endliche Akzeptoren}
\begin{itemize}
    \item Immer genau ein Bit als Ausgabe:\\
    $\forall z \in Z: h(z)\in Y=\set{\word{0}, \word{1}}$
    \\Interpretiert wird \word{1} als \interpretation{gut/korrekt} und \word{0} als \interpretation{schlecht/falsch}
\end{itemize}

\subsubsection{Formalisierung}
\begin{itemize}
    \item Spezifikation einer Menge $F$: \important{Akzeptierende Zustände}
    \item $F=\set{z\in Z\mid h(z)=\word{1}}$
    \item Alle $z\in (Z\setminus F)$ sind \important{ablehnende Zustände}
    \item ablehnende Zustände werden im Schaubild mit einem Kreis gezeichnet, akzeptierende Zustände bekommen einen \anfuehrung{Doppelkringel}
\end{itemize}

\subsubsection{Akzeptiert und Ablehnen}
\begin{itemize}
    \item Ein Wort $w\in X^*$ wird \important{akzeptiert}, falls $f_*(z_0, w)\in F$
    \item Ein Wort $w\in X^*$ wird \important{abgelehnt}, falls $f_*(z_0, w)\notin F$
    \item Die von einem Akzeptor $A=(Z,z_0,X,f,F)$ \important{akzeptierte} oder \important{erkannte formale Sprache} ist\\
    $L(A)=\set{w\in X^*\mid f_*(z_0,w)\in F}$
    \item Es handelt sich um ganz einfache Syntaxanalyse.
\end{itemize}

\subsubsection{Nicht erkennbare Formale Sprachen}
\example{Die formale Sprache $L=\set{\word{a}^k\word{b}^k \mid k\in\Nz}$ kann nicht von einem endlichen Akzeptor erkannt werden.}\\
Beweisansatz: Wähle $k=$Anzahl der Zustände des Akzeptors.\\
Dann \textbf{muss} der Akzeptor irgendwo \anfuehrung{im Kreis laufen}, kann also nicht mehr mitzählen, wie oft er bereits im Kreis gelaufen ist. Dadurch lassen sich Worte konstruieren, die fälschlicher Weise als korrekt angenommen werden.

%Seite 16

\end{document}